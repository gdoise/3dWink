<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visionneuse 3D Par Occlusion Oculaire - Mode D√©tection</title>
    <style>
        /* D√©but du CSS int√©gr√© */
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 20px;
            background-color: #f0f0f0;
            color: #333;
        }

        h1 {
            color: #0056b3;
            margin-bottom: 20px;
        }

        .controls {
            margin-bottom: 20px;
            text-align: center;
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            width: 90%;
            max-width: 680px;
        }

        button {
            padding: 12px 25px;
            font-size: 18px;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.3s ease;
            margin-bottom: 15px;
        }

        button:hover {
            background-color: #0056b3;
        }

        p {
            margin: 8px 0;
        }

        input[type="radio"] {
            margin-right: 5px;
        }

        label {
            font-size: 1rem;
        }

        #status {
            margin-top: 10px;
            font-weight: bold;
            color: #555;
        }

        #statusLog {
            width: 90%;
            max-width: 500px;
            height: 200px;
            margin-top: 15px;
            padding: 10px;
            font-size: 0.9em;
            border: 1px solid #ddd;
            background-color: #f9f9f9;
            resize: vertical;
            font-family: monospace;
            white-space: pre-wrap;
            overflow-y: scroll;
            text-align: left; /* Align left for logs */
        }

        .video-container {
            position: relative;
            width: 640px;
            height: 480px;
            border: 2px solid #a0a0a0;
            background-color: black;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 25px;
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
        }

        #outputCanvas {
            width: 100%;
            height: 100%;
            display: block;
        }

        .param-group {
            margin-top: 20px;
            border-top: 1px solid #eee;
            padding-top: 15px;
            text-align: left;
            padding-left: 20px;
            padding-right: 20px;
        }

        .param-group label, .param-group input[type="range"] {
            display: block;
            width: calc(100% - 20px);
            margin-bottom: 8px;
        }

        .param-group span {
            font-weight: bold;
            display: inline-block;
            width: 150px; /* Alignement */
        }
        /* Fin du CSS int√©gr√© */
    </style>
</head>
<body>
    <h1>üëÄ Visionneuse 3D Interactive (Mode D√©tection / D√©bug) üëÄ</h1>

    <div class="controls">
        <div class="param-group">
            <h3>Choix du mode de chargement FaceMesh :</h3>
            <p>
                <input type="radio" id="modelVersionV1" name="modelLoadVersion" value="v1" checked>
                <label for="modelVersionV1">Backend par d√©faut (v1) - *Recommand√© pour GPU*</label>
            </p>
            <p>
                <input type="radio" id="modelVersionV2" name="modelLoadVersion" value="v2">
                <label for="modelVersionV2">Forcer Backend CPU (v2) - *Pour diagnostic des 'NaN'*</label>
            </p>
        </div>
        
        <button id="startButton">D√©marrer la Webcam</button>
        <p id="status">Statut : En attente de d√©marrage...</p>
        <textarea id="statusLog" rows="10" cols="50" readonly></textarea>
        
        <div class="param-group">
            <h3>Param√®tres de D√©tection :</h3>
            <p>
                <label for="visibilityThreshold">
                    <span>Seuil de visibilit√© (Z-coord) :</span>
                    <input type="range" id="visibilityThreshold" min="0" max="1" step="0.01" value="0.05">
                    <span id="visibilityThresholdValue">0.05</span>
                </label>
            </p>
            <p>
                <label for="minEyePointsForVisibility">
                    <span>Min. points par ≈ìil visible :</span>
                    <input type="range" id="minEyePointsForVisibility" min="1" max="50" step="1" value="10">
                    <span id="minEyePointsForVisibilityValue">10</span>
                </label>
            </p>
            <p>
                <label for="faceDetectionConfidence">
                    <span>Confiance min. d√©tection visage :</span>
                    <input type="range" id="faceDetectionConfidence" min="0" max="1" step="0.05" value="0.9">
                    <span id="faceDetectionConfidenceValue">0.9</span>
                </label>
            </p>
            <p>
                <label for="frameRate">
                    <span>Fr√©quence d'analyse (ms) :</span>
                    <input type="range" id="frameRate" min="10" max="500" step="10" value="50">
                    <span id="frameRateValue">50 ms</span>
                </label>
            </p>
             <p>
                <input type="checkbox" id="showLandmarks" checked>
                <label for="showLandmarks">Afficher les points de d√©tection</label>
            </p>
            <p>
                <input type="checkbox" id="showBoundingBox">
                <label for="showBoundingBox">Afficher le cadre du visage</label>
            </p>
        </div>

        <h3>Mode d'affichage (deux yeux visibles) :</h3>
        <p>
            <input type="radio" id="modeBlack" name="twoEyesMode" value="black" checked>
            <label for="modeBlack">√âcran noir</label>
        </p>
        <p>
            <input type="radio" id="modeSideBySide" name="twoEyesMode" value="sidebyside">
            <label for="modeSideBySide">C√¥t√© √† c√¥t√©</label>
        </p>
        <p>
            <input type="radio" id="modeMono" name="twoEyesMode" value="mono">
            <label for="modeMono">Image unique (gauche)</label>
        </p>
    </div>

    <div class="video-container">
        <video id="webcamVideo" autoplay playsinline style="display: none;"></video>
        <canvas id="outputCanvas"></canvas>
    </div>
    <! -- Il est tr√®s possible que la version 4.x de TFJS ait des changements internes qui ne sont pas enti√®rement compatibles avec la version 1.0.1 du mod√®le face-landmarks-detection
            src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.x/dist/tf.min.js"  Donc on downgrade tensorflow vers: -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.1/dist/face-landmarks-detection.min.js"></script>
    

    <script>
        /* D√©but du JavaScript int√©gr√© */
        const webcamVideo = document.getElementById('webcamVideo');
        const outputCanvas = document.getElementById('outputCanvas');
        const ctx = outputCanvas.getContext('2d');
        const startButton = document.getElementById('startButton');
        const statusLogElement = document.getElementById('statusLog');
        const statusElement = document.getElementById('status');

        // √âl√©ments pour les param√®tres
        const visibilityThresholdSlider = document.getElementById('visibilityThreshold');
        const visibilityThresholdValueSpan = document.getElementById('visibilityThresholdValue');
        const minEyePointsForVisibilitySlider = document.getElementById('minEyePointsForVisibility');
        const minEyePointsForVisibilityValueSpan = document.getElementById('minEyePointsForVisibilityValue');
        const faceDetectionConfidenceSlider = document.getElementById('faceDetectionConfidence');
        const faceDetectionConfidenceValueSpan = document.getElementById('faceDetectionConfidenceValue');
        const frameRateSlider = document.getElementById('frameRate');
        const frameRateValueSpan = document.getElementById('frameRateValue');
        const showLandmarksCheckbox = document.getElementById('showLandmarks');
        const showBoundingBoxCheckbox = document.getElementById('showBoundingBox');

        let model;
        let animationFrameId;
        let lastStatusMessage = '';
        let lastDetectionTime = 0;

        // Param√®tres configurables
        let visibilityThreshold = parseFloat(visibilityThresholdSlider.value);
        let minEyePointsForVisibility = parseInt(minEyePointsForVisibilitySlider.value);
        let faceDetectionConfidence = parseFloat(faceDetectionConfidenceSlider.value);
        let desiredFrameRate = parseInt(frameRateSlider.value);
        let showLandmarks = showLandmarksCheckbox.checked;
        let showBoundingBox = showBoundingBoxCheckbox.checked;

        // Mise √† jour des valeurs affich√©es des sliders
        visibilityThresholdSlider.oninput = () => {
            visibilityThreshold = parseFloat(visibilityThresholdSlider.value);
            visibilityThresholdValueSpan.textContent = visibilityThreshold;
        };
        minEyePointsForVisibilitySlider.oninput = () => {
            minEyePointsForVisibility = parseInt(minEyePointsForVisibilitySlider.value);
            minEyePointsForVisibilityValueSpan.textContent = minEyePointsForVisibility;
        };
        faceDetectionConfidenceSlider.oninput = () => {
            faceDetectionConfidence = parseFloat(faceDetectionConfidenceSlider.value);
            faceDetectionConfidenceValueSpan.textContent = faceDetectionConfidence;
        };
        frameRateSlider.oninput = () => {
            desiredFrameRate = parseInt(frameRateSlider.value);
            frameRateValueSpan.textContent = `${desiredFrameRate} ms`;
        };
        showLandmarksCheckbox.onchange = () => {
            showLandmarks = showLandmarksCheckbox.checked;
        };
        showBoundingBoxCheckbox.onchange = () => {
            showBoundingBox = showBoundingBoxCheckbox.checked;
        };

        // Dimensions du canvas
        const CANVAS_WIDTH = 640;
        const CANVAS_HEIGHT = 480;

        outputCanvas.width = CANVAS_WIDTH;
        outputCanvas.height = CANVAS_HEIGHT;

        // Chargement des images 3D (remplacez par vos propres chemins !)
        const imageLeft = new Image();
        imageLeft.src = 'photos3d/gImgMer1.jpg';
        const imageRight = new Image();
        imageRight.src = 'photos3d/dImgMer1.jpg';

        let imagesLoaded = false;
        let imagesToLoad = 2;

        function imageLoaded() {
            imagesToLoad--;
            if (imagesToLoad === 0) {
                imagesLoaded = true;
                updateStatusLog('Images 3D charg√©es. Pr√™t.');
            }
        }

        imageLeft.onload = imageLoaded;
        imageRight.onload = imageLoaded;
        imageLeft.onerror = () => { updateStatusLog('Erreur: Impossible de charger l\'image gauche.'); };
        imageRight.onerror = () => { updateStatusLog('Erreur: Impossible de charger l\'image droite.'); };

        function updateStatusLog(message) {
            const now = new Date();
            const timeString = now.toLocaleTimeString('fr-FR', {hour: '2-digit', minute:'2-digit', second:'2-digit'});
            const fullMessage = `[${timeString}] ${message}`;

            // √âviter de r√©p√©ter le m√™me message, sauf si c'est le statut principal
            if (message !== lastStatusMessage || message.includes('Aucun visage d√©tect√©') || message.includes('Visage d√©tect√©')) {
                statusLogElement.value += fullMessage + '\n';
                statusLogElement.scrollTop = statusLogElement.scrollHeight;
                lastStatusMessage = message;
            }
            statusElement.textContent = `Statut : ${message.split('\n')[0]}`;
        }

        async function setupWebcam() {
            updateStatusLog('D√©marrage de la webcam...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                webcamVideo.srcObject = stream;
                return new Promise((resolve) => {
                    webcamVideo.onloadedmetadata = () => {
                        webcamVideo.play();
                        resolve();
                    };
                });
            } catch (error) {
                console.error('Erreur d\'acc√®s √† la webcam:', error);
                updateStatusLog(`Erreur: Acc√®s √† la webcam refus√© ou impossible. (${error.name} - ${error.message || 'Cause inconnue'})`);
                alert('Impossible d\'acc√©der √† la webcam. Assurez-vous qu\'elle est connect√©e et que vous avez accord√© la permission.');
            }
        }

        // V1 : Chargement par d√©faut (priorise WebGL/GPU)
        async function loadFaceMeshModel_v1() {
            updateStatusLog('Chargement du mod√®le FaceMesh (v1 - Backend par d√©faut)...');
            const detectorConfig = {
                runtime: 'tfjs',
            };
            try {
                // S'assurer que TensorFlow.js est pr√™t avant de cr√©er le d√©tecteur
                await tf.ready();
                console.log('TFJS backend (v1):', tf.getBackend());
                model = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, detectorConfig);
                updateStatusLog('Mod√®le FaceMesh (v1) charg√© avec succ√®s.');
                console.log('FaceMesh model loaded successfully with TFJS runtime (v1).');
            } catch (error) {
                console.error('Erreur lors du chargement du mod√®le FaceMesh (v1):', error);
                updateStatusLog(`Erreur: Impossible de charger le mod√®le FaceMesh (v1). (${error.message || 'V√©rifiez la console.'})`);
            }
        }

        // V2 : Force le backend CPU
        async function loadFaceMeshModel_v2() {
            updateStatusLog('Chargement du mod√®le FaceMesh (v2 - Forcer CPU)...');
            try {
                // Tenter de forcer le backend CPU
                await tf.setBackend('cpu');
                await tf.ready(); // S'assurer que le backend est pr√™t
                console.log('TFJS backend (v2):', tf.getBackend()); // V√©rifier si c'est bien CPU
                const detectorConfig = {
                    runtime: 'tfjs',
                };
                model = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, detectorConfig);
                updateStatusLog('Mod√®le FaceMesh (v2) charg√© avec backend CPU.');
                console.log('FaceMesh model loaded successfully with TFJS runtime and CPU backend (v2).');
            } catch (error) {
                console.error('Erreur lors du chargement du mod√®le FaceMesh (v2):', error);
                updateStatusLog(`Erreur: Impossible de charger le mod√®le FaceMesh (v2). (${error.message || 'V√©rifiez la console.'})`);
            }
        }
        
        // Indices des points cl√©s pour les contours des yeux FaceMesh
        const LEFT_EYE_CONTOUR_INDICES = [
            33, 7, 163, 144, 145, 153, 154, 155, 133,
            246, 161, 160, 159, 158, 157, 173,
        ];
        const RIGHT_EYE_CONTOUR_INDICES = [
            362, 382, 381, 380, 374, 373, 390, 249,
            466, 388, 387, 386, 385, 384, 398,
        ];

        const checkEyeOcclusion = (faceMesh, indices) => {
            if (!faceMesh) return false; // Ajout d'une v√©rification au cas o√π scaledMesh est null ou undefined
            let detectedPointsInEye = 0;
            for (const idx of indices) {
                // V√©rifier si le point existe et si sa coordonn√©e Z est sup√©rieure au seuil
                if (faceMesh[idx] && !isNaN(faceMesh[idx][2]) && faceMesh[idx][2] > visibilityThreshold) {
                    detectedPointsInEye++;
                }
            }
            return detectedPointsInEye >= minEyePointsForVisibility;
        };

        // Fonction pour dessiner les points d√©tect√©s sur le canvas
        function drawLandmarks(landmarks, color = 'lime') {
            if (!landmarks || landmarks.length === 0) return;
            ctx.fillStyle = color;
            for (const landmark of landmarks) {
                // Assurez-vous que les coordonn√©es ne sont pas NaN
                if (!isNaN(landmark[0]) && !isNaN(landmark[1])) {
                    const x = landmark[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                    const y = landmark[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                    ctx.beginPath();
                    ctx.arc(x, y, 2, 0, 2 * Math.PI);
                    ctx.fill();
                }
            }
        }
        
        // Nouvelle fonction pour dessiner un cadre de d√©limitation √† partir des coordonn√©es brutes
        function drawBoundingBoxFromRaw(box, color = 'red') {
            if (isNaN(box.xMin) || isNaN(box.yMin) || isNaN(box.width) || isNaN(box.height)) {
                console.warn('Bounding box contient des NaN, impossible de dessiner.');
                return;
            }
            ctx.strokeStyle = color;
            ctx.lineWidth = 2;
            const startX = box.xMin * (CANVAS_WIDTH / webcamVideo.videoWidth);
            const startY = box.yMin * (CANVAS_HEIGHT / webcamVideo.videoHeight);
            const width = box.width * (CANVAS_WIDTH / webcamVideo.videoWidth);
            const height = box.height * (CANVAS_HEIGHT / webcamVideo.videoHeight);
            ctx.strokeRect(startX, startY, width, height);
            ctx.fillStyle = color;
            ctx.font = '12px Arial';
            if (!isNaN(box.score)) {
                ctx.fillText(`Confiance: ${box.score.toFixed(2)}`, startX + 5, startY + 15);
            }
        }

        async function detectAndDraw() {
            // console.log('detectAndDraw: Appel√©e.'); // Trop verbeux, √† d√©sactiver

            const now = performance.now();
            if (now - lastDetectionTime < desiredFrameRate) {
                animationFrameId = requestAnimationFrame(detectAndDraw);
                return;
            }
            lastDetectionTime = now;
        
            if (!model || !webcamVideo.srcObject || !imagesLoaded) {
                let reason = '';
                if (!model) reason += 'Mod√®le non charg√©. ';
                if (!webcamVideo.srcObject) reason += 'Webcam non pr√™te. ';
                if (!imagesLoaded) reason += 'Images 3D non charg√©es. ';
                // console.log(`detectAndDraw: Terminaison anticip√©e - ${reason}`); // Trop verbeux, √† d√©sactiver
                animationFrameId = requestAnimationFrame(detectAndDraw);
                return;
            }
        
            // --- Dessine la vid√©o de la webcam sur le canvas en premier ---
            ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
            
            if (webcamVideo.videoWidth > 0 && webcamVideo.videoHeight > 0) {
                ctx.drawImage(webcamVideo, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
            } else {
                console.warn('Webcam video dimensions are zero, cannot draw yet.');
            }
        
            // Ex√©cution de la d√©tection FaceMesh
            const predictions = await model.estimateFaces(webcamVideo, { flipHorizontal: false, minDetectionConfidence: faceDetectionConfidence });

            // console.log('Nombre de pr√©dictions FaceMesh:', predictions.length); // Utile pour le d√©bogage initial
            
            let leftEyeVisible = false;
            let rightEyeVisible = false;
            let currentStatusMessage = 'Aucun visage d√©tect√©.';

            if (predictions.length > 0) {
                const face = predictions[0];
                const scaledMesh = face.scaledMesh; // Les 468 points d√©tect√©s

                if (scaledMesh && scaledMesh.length > 0 && !isNaN(scaledMesh[0][0])) { // V√©rifie le premier point pour NaN
                    // Calculez min/max X et Y √† partir des points d√©tect√©s pour un bounding box "s√ªr"
                    let minX = Infinity;
                    let minY = Infinity;
                    let maxX = -Infinity;
                    let maxY = -Infinity;
                
                    for (const point of scaledMesh) {
                         // V√©rifie que les coordonn√©es sont num√©riques avant de les utiliser
                        if (!isNaN(point[0]) && !isNaN(point[1])) {
                            minX = Math.min(minX, point[0]);
                            minY = Math.min(minY, point[1]);
                            maxX = Math.max(maxX, point[0]);
                            maxY = Math.max(maxY, point[1]);
                        }
                    }
                
                    const customBoundingBox = {
                        xMin: minX,
                        yMin: minY,
                        width: maxX - minX,
                        height: maxY - minY,
                        score: face.box ? face.box.score : 1.0 // Utilise le score existant ou un par d√©faut
                    };
                
                    if (showBoundingBox) {
                        drawBoundingBoxFromRaw(customBoundingBox, 'cyan');
                    }

                    leftEyeVisible = checkEyeOcclusion(scaledMesh, LEFT_EYE_CONTOUR_INDICES);
                    rightEyeVisible = checkEyeOcclusion(scaledMesh, RIGHT_EYE_CONTOUR_INDICES);
                    
                    if (showLandmarks) {
                        drawLandmarks(scaledMesh, 'rgba(255, 255, 0, 0.5)'); 

                        // Dessin des points des yeux avec leur valeur Z
                        for(const idx of LEFT_EYE_CONTOUR_INDICES) {
                            if(scaledMesh[idx] && !isNaN(scaledMesh[idx][0])) {
                                const pt = scaledMesh[idx];
                                const x = pt[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                                const y = pt[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                                ctx.fillStyle = 'red';
                                ctx.beginPath();
                                ctx.arc(x, y, 3, 0, 2 * Math.PI);
                                ctx.fill();
                                ctx.font = '10px Arial';
                                ctx.fillText(pt[2].toFixed(2), x + 5, y - 5); 
                            }
                        }
                        for(const idx of RIGHT_EYE_CONTOUR_INDICES) {
                            if(scaledMesh[idx] && !isNaN(scaledMesh[idx][0])) {
                                const pt = scaledMesh[idx];
                                const x = pt[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                                const y = pt[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                                ctx.fillStyle = 'blue';
                                ctx.beginPath();
                                ctx.arc(x, y, 3, 0, 2 * Math.PI);
                                ctx.fill();
                                ctx.font = '10px Arial';
                                ctx.fillText(pt[2].toFixed(2), x + 5, y - 5); 
                            }
                        }
                    }

                    const leftEyePointsCount = scaledMesh.filter((p, i) => LEFT_EYE_CONTOUR_INDICES.includes(i) && !isNaN(p[2]) && p[2] > visibilityThreshold).length;
                    const rightEyePointsCount = scaledMesh.filter((p, i) => RIGHT_EYE_CONTOUR_INDICES.includes(i) && !isNaN(p[2]) && p[2] > visibilityThreshold).length;
                    
                    currentStatusMessage = `Visage d√©tect√© (Conf: ${customBoundingBox.score.toFixed(2)}). `;
                    currentStatusMessage += `≈íil G: ${leftEyeVisible ? 'Visible' : 'Masqu√©'} (${leftEyePointsCount}/${LEFT_EYE_CONTOUR_INDICES.length}), `;
                    currentStatusMessage += `≈íil D: ${rightEyeVisible ? 'Visible' : 'Masqu√©'} (${rightEyePointsCount}/${RIGHT_EYE_CONTOUR_INDICES.length})`;

                } else {
                    currentStatusMessage = 'Visage d√©tect√©, mais donn√©es de points cl√©s absentes, incompl√®tes ou invalides. Ajustez la confiance ou l\'√©clairage.';
                }

            } else {
                currentStatusMessage = 'Aucun visage d√©tect√©.';
            }

            // Affichage des images 3D si les landmarks ne sont pas affich√©s
            if (!showLandmarks) {
                // Si showLandmarks est d√©sactiv√©, on efface le canvas pour afficher les images 3D
                ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT); 

                if (leftEyeVisible && !rightEyeVisible) {
                    ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                    currentStatusMessage += ' -> Image Gauche';
                } else if (!leftEyeVisible && rightEyeVisible) {
                    ctx.drawImage(imageRight, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                    currentStatusMessage += ' -> Image Droite';
                } else {
                    const twoEyesMode = document.querySelector('input[name="twoEyesMode"]:checked').value;
                    if (twoEyesMode === 'black') {
                        ctx.fillStyle = 'black';
                        ctx.fillRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> √âcran Noir';
                    } else if (twoEyesMode === 'sidebyside') {
                        ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH / 2, CANVAS_HEIGHT);
                        ctx.drawImage(imageRight, CANVAS_WIDTH / 2, 0, CANVAS_WIDTH / 2, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> C√¥t√© √† C√¥t√©';
                    } else if (twoEyesMode === 'mono') {
                        ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> Image Unique';
                    }
                }
            } else {
                // Si showLandmarks est activ√©, la vid√©o de la webcam est d√©j√† dessin√©e.
                // On ajoute juste l'information de l'√©tat des yeux au statut.
                // Le message est d√©j√† construit plus haut.
            }

            updateStatusLog(currentStatusMessage);

            animationFrameId = requestAnimationFrame(detectAndDraw);
        }

        startButton.addEventListener('click', async () => {
            statusLogElement.value = '';
            lastStatusMessage = '';
            updateStatusLog('D√©marrage de l\'application...');
        
            // D√©terminer quelle version de loadFaceMeshModel appeler
            const selectedVersion = document.querySelector('input[name="modelLoadVersion"]:checked').value;
            if (selectedVersion === 'v1') {
                await loadFaceMeshModel_v1();
            } else { // 'v2'
                await loadFaceMeshModel_v2();
            }
            
            if (!model) {
                updateStatusLog('Impossible de continuer sans le mod√®le FaceMesh. Corrigez les erreurs.');
                console.error('Model not loaded, aborting startup.'); 
                return;
            }
        
            await setupWebcam();
            if (!webcamVideo.srcObject) {
                updateStatusLog('Impossible de continuer sans l\'acc√®s √† la webcam. Corrigez les permissions.');
                console.error('Webcam not ready, aborting startup.'); 
                return;
            }
             
            webcamVideo.onloadeddata = () => { 
                console.log('Webcam video loadeddata event fired. Starting detection loop.');
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                }
                updateStatusLog('Webcam d√©marr√©e. D√©tection en cours...');
                animationFrameId = requestAnimationFrame(detectAndDraw);
            };
            // Fallback au cas o√π onloadeddata ne se d√©clenche pas (parfois un probl√®me de navigateur)
            setTimeout(() => {
                if (!animationFrameId && webcamVideo.srcObject) {
                    console.warn("Webcam loadeddata event did not fire within expected time. Forcing detectAndDraw start.");
                    updateStatusLog('Webcam d√©marr√©e (force). D√©tection en cours...');
                    animationFrameId = requestAnimationFrame(detectAndDraw);
                }
            }, 3000); 
        });
        /* Fin du JavaScript int√©gr√© */
    </script>
</body>
</html>
