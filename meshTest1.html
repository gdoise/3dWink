<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visionneuse 3D Par Occlusion Oculaire - Mode D√©tection</title>
    <style>
        /* D√©but du CSS int√©gr√© */
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 20px;
            background-color: #f0f0f0;
            color: #333;
        }

        h1 {
            color: #0056b3;
            margin-bottom: 20px;
        }

        .controls {
            margin-bottom: 20px;
            text-align: center;
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            width: 90%;
            max-width: 680px;
        }

        button {
            padding: 12px 25px;
            font-size: 18px;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.3s ease;
            margin-bottom: 15px;
        }

        button:hover {
            background-color: #0056b3;
        }

        p {
            margin: 8px 0;
        }

        input[type="radio"] {
            margin-right: 5px;
        }

        label {
            font-size: 1rem;
        }

        #status {
            margin-top: 10px;
            font-weight: bold;
            color: #555;
        }

        #statusLog {
            width: 90%;
            max-width: 500px;
            height: 200px;
            margin-top: 15px;
            padding: 10px;
            font-size: 0.9em;
            border: 1px solid #ddd;
            background-color: #f9f9f9;
            resize: vertical;
            font-family: monospace;
            white-space: pre-wrap;
            overflow-y: scroll;
            text-align: left; /* Align left for logs */
        }

        .video-container {
            position: relative;
            width: 640px;
            height: 480px;
            border: 2px solid #a0a0a0;
            background-color: black;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 25px;
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
        }

        #outputCanvas {
            width: 100%;
            height: 100%;
            display: block;
        }

        .param-group {
            margin-top: 20px;
            border-top: 1px solid #eee;
            padding-top: 15px;
            text-align: left;
            padding-left: 20px;
            padding-right: 20px;
        }

        .param-group label, .param-group input[type="range"] {
            display: block;
            width: calc(100% - 20px);
            margin-bottom: 8px;
        }

        .param-group span {
            font-weight: bold;
            display: inline-block;
            width: 150px; /* Alignement */
        }

        /* Fin du CSS int√©gr√© */
    </style>
</head>
<body>
    <h1>üëÄ Visionneuse 3D Interactive (Mode D√©tection/D√©bug) üëÄ</h1>

    <div class="controls">
        <button id="startButton">D√©marrer la Webcam</button>
        <p id="status">Statut : En attente de d√©marrage...</p>
        <textarea id="statusLog" rows="10" cols="50" readonly></textarea>
        
        <div class="param-group">
            <h3>Param√®tres de D√©tection :</h3>
            <p>
                <label for="visibilityThreshold">
                    <span>Seuil de visibilit√© (Z-coord) :</span>
                    <input type="range" id="visibilityThreshold" min="0" max="1" step="0.01" value="0.05">
                    <span id="visibilityThresholdValue">0.05</span>
                </label>
            </p>
            <p>
                <label for="minEyePointsForVisibility">
                    <span>Min. points par ≈ìil visible :</span>
                    <input type="range" id="minEyePointsForVisibility" min="1" max="50" step="1" value="10">
                    <span id="minEyePointsForVisibilityValue">10</span>
                </label>
            </p>
            <p>
                <label for="faceDetectionConfidence">
                    <span>Confiance min. d√©tection visage :</span>
                    <input type="range" id="faceDetectionConfidence" min="0" max="1" step="0.05" value="0.9">
                    <span id="faceDetectionConfidenceValue">0.9</span>
                </label>
            </p>
            <p>
                <label for="frameRate">
                    <span>Fr√©quence d'analyse (ms) :</span>
                    <input type="range" id="frameRate" min="10" max="500" step="10" value="50">
                    <span id="frameRateValue">50 ms</span>
                </label>
            </p>
             <p>
                <input type="checkbox" id="showLandmarks" checked>
                <label for="showLandmarks">Afficher les points de d√©tection</label>
            </p>
            <p>
                <input type="checkbox" id="showBoundingBox">
                <label for="showBoundingBox">Afficher le cadre du visage</label>
            </p>
        </div>

        <h3>Mode d'affichage (deux yeux visibles) :</h3>
        <p>
            <input type="radio" id="modeBlack" name="twoEyesMode" value="black" checked>
            <label for="modeBlack">√âcran noir</label>
        </p>
        <p>
            <input type="radio" id="modeSideBySide" name="twoEyesMode" value="sidebyside">
            <label for="modeSideBySide">C√¥t√© √† c√¥te</label>
        </p>
        <p>
            <input type="radio" id="modeMono" name="twoEyesMode" value="mono">
            <label for="modeMono">Image unique (gauche)</label>
        </p>
    </div>

    <div class="video-container">
        <video id="webcamVideo" autoplay playsinline style="display: none;"></video>
        <canvas id="outputCanvas"></canvas>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.x/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.1/dist/face-landmarks-detection.min.js"></script>

    <script>
        /* D√©but du JavaScript int√©gr√© */
        const webcamVideo = document.getElementById('webcamVideo');
        const outputCanvas = document.getElementById('outputCanvas');
        const ctx = outputCanvas.getContext('2d');
        const startButton = document.getElementById('startButton');
        const statusLogElement = document.getElementById('statusLog');
        const statusElement = document.getElementById('status');

        // √âl√©ments pour les param√®tres
        const visibilityThresholdSlider = document.getElementById('visibilityThreshold');
        const visibilityThresholdValueSpan = document.getElementById('visibilityThresholdValue');
        const minEyePointsForVisibilitySlider = document.getElementById('minEyePointsForVisibility');
        const minEyePointsForVisibilityValueSpan = document.getElementById('minEyePointsForVisibilityValue');
        const faceDetectionConfidenceSlider = document.getElementById('faceDetectionConfidence'); // Nouveau slider
        const faceDetectionConfidenceValueSpan = document.getElementById('faceDetectionConfidenceValue'); // Nouveau span
        const frameRateSlider = document.getElementById('frameRate');
        const frameRateValueSpan = document.getElementById('frameRateValue');
        const showLandmarksCheckbox = document.getElementById('showLandmarks');
        const showBoundingBoxCheckbox = document.getElementById('showBoundingBox'); // Nouvelle checkbox


        let model;
        let animationFrameId;
        let lastStatusMessage = '';
        let lastDetectionTime = 0;

        // Param√®tres configurables
        let visibilityThreshold = parseFloat(visibilityThresholdSlider.value);
        let minEyePointsForVisibility = parseInt(minEyePointsForVisibilitySlider.value);
        let faceDetectionConfidence = parseFloat(faceDetectionConfidenceSlider.value); // Nouvelle variable
        let desiredFrameRate = parseInt(frameRateSlider.value);
        let showLandmarks = showLandmarksCheckbox.checked;
        let showBoundingBox = showBoundingBoxCheckbox.checked; // Nouvelle variable


        // Mise √† jour des valeurs affich√©es des sliders
        visibilityThresholdSlider.oninput = () => {
            visibilityThreshold = parseFloat(visibilityThresholdSlider.value);
            visibilityThresholdValueSpan.textContent = visibilityThreshold;
        };
        minEyePointsForVisibilitySlider.oninput = () => {
            minEyePointsForVisibility = parseInt(minEyePointsForVisibilitySlider.value);
            minEyePointsForVisibilityValueSpan.textContent = minEyePointsForVisibility;
        };
        faceDetectionConfidenceSlider.oninput = () => { // Nouveau gestionnaire
            faceDetectionConfidence = parseFloat(faceDetectionConfidenceSlider.value);
            faceDetectionConfidenceValueSpan.textContent = faceDetectionConfidence;
        };
        frameRateSlider.oninput = () => {
            desiredFrameRate = parseInt(frameRateSlider.value);
            frameRateValueSpan.textContent = `${desiredFrameRate} ms`;
        };
        showLandmarksCheckbox.onchange = () => {
            showLandmarks = showLandmarksCheckbox.checked;
        };
        showBoundingBoxCheckbox.onchange = () => { // Nouveau gestionnaire
            showBoundingBox = showBoundingBoxCheckbox.checked;
        };


        // Dimensions du canvas
        const CANVAS_WIDTH = 640;
        const CANVAS_HEIGHT = 480;

        outputCanvas.width = CANVAS_WIDTH;
        outputCanvas.height = CANVAS_HEIGHT;

        // Chargement des images 3D (remplacez par vos propres chemins !)
        const imageLeft = new Image();
        imageLeft.src = 'https://via.placeholder.com/640x480/FF0000/FFFFFF?text=Image+Gauche';
        const imageRight = new Image();
        imageRight.src = 'https://via.placeholder.com/640x480/0000FF/FFFFFF?text=Image+Droite';

        let imagesLoaded = false;
        let imagesToLoad = 2;

        function imageLoaded() {
            imagesToLoad--;
            if (imagesToLoad === 0) {
                imagesLoaded = true;
                updateStatusLog('Images 3D charg√©es. Pr√™t.');
            }
        }

        imageLeft.onload = imageLoaded;
        imageRight.onload = imageLoaded;
        imageLeft.onerror = () => { updateStatusLog('Erreur: Impossible de charger l\'image gauche.'); };
        imageRight.onerror = () => { updateStatusLog('Erreur: Impossible de charger l\'image droite.'); };

        function updateStatusLog(message) {
            const now = new Date();
            const timeString = now.toLocaleTimeString('fr-FR', {hour: '2-digit', minute:'2-digit', second:'2-digit'});
            const fullMessage = `[${timeString}] ${message}`;

            if (message !== lastStatusMessage) {
                statusLogElement.value += fullMessage + '\n';
                statusLogElement.scrollTop = statusLogElement.scrollHeight;
                lastStatusMessage = message;
            }
            statusElement.textContent = `Statut : ${message.split('\n')[0]}`;
        }

        async function setupWebcam() {
            updateStatusLog('D√©marrage de la webcam...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                webcamVideo.srcObject = stream;
                return new Promise((resolve) => {
                    webcamVideo.onloadedmetadata = () => {
                        webcamVideo.play();
                        resolve();
                    };
                });
            } catch (error) {
                console.error('Erreur d\'acc√®s √† la webcam:', error);
                updateStatusLog(`Erreur: Acc√®s √† la webcam refus√© ou impossible. (${error.name} - ${error.message || 'Cause inconnue'})`);
                alert('Impossible d\'acc√©der √† la webcam. Assurez-vous qu\'elle est connect√©e et que vous avez accord√© la permission.');
            }
        }

        async function loadFaceMeshModel() {
            updateStatusLog('Chargement du mod√®le FaceMesh...');
            const detectorConfig = {
                runtime: 'tfjs',
            };
            try {
                model = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, detectorConfig);
                updateStatusLog('Mod√®le FaceMesh charg√©.');
                console.log('FaceMesh model loaded successfully with TFJS runtime.');
            } catch (error) {
                console.error('Erreur lors du chargement du mod√®le FaceMesh:', error);
                updateStatusLog(`Erreur: Impossible de charger le mod√®le FaceMesh. (${error.message || 'V√©rifiez la console.'})`);
            }
        }

        // Indices des points cl√©s pour les contours des yeux FaceMesh
        const LEFT_EYE_CONTOUR_INDICES = [
            33, 7, 163, 144, 145, 153, 154, 155, 133,
            246, 161, 160, 159, 158, 157, 173,
        ];
        const RIGHT_EYE_CONTOUR_INDICES = [
            362, 382, 381, 380, 374, 373, 390, 249,
            466, 388, 387, 386, 385, 384, 398,
        ];

        const checkEyeOcclusion = (faceMesh, indices) => {
            let detectedPointsInEye = 0;
            for (const idx of indices) {
                if (faceMesh[idx] && faceMesh[idx][2] > visibilityThreshold) { // [2] est la coordonn√©e Z (confiance/visibilit√©)
                    detectedPointsInEye++;
                }
            }
            return detectedPointsInEye >= minEyePointsForVisibility;
        };

        // Fonction pour dessiner les points d√©tect√©s sur le canvas
        function drawLandmarks(landmarks, color = 'lime') {
            if (!landmarks) return;
            ctx.fillStyle = color;
            for (const landmark of landmarks) {
                const x = landmark[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                const y = landmark[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                ctx.beginPath();
                ctx.arc(x, y, 2, 0, 2 * Math.PI);
                ctx.fill();
            }
        }
        
        // Fonction pour dessiner un rectangle de d√©limitation
        function drawBoundingBox(box, color = 'red') {
            ctx.strokeStyle = color;
            ctx.lineWidth = 2;
            // Assurez-vous que les coordonn√©es du bounding box sont correctement mises √† l'√©chelle pour le canvas
            const startX = box.xMin * (CANVAS_WIDTH / webcamVideo.videoWidth);
            const startY = box.yMin * (CANVAS_HEIGHT / webcamVideo.videoHeight);
            const width = box.width * (CANVAS_WIDTH / webcamVideo.videoWidth);
            const height = box.height * (CANVAS_HEIGHT / webcamVideo.videoHeight);
            ctx.strokeRect(startX, startY, width, height);
            ctx.fillStyle = color;
            ctx.font = '12px Arial';
            ctx.fillText(`Confiance: ${box.score.toFixed(2)}`, startX + 5, startY + 15);
        }

        async function detectAndDraw() {
            console.log('detectAndDraw: Appel√©e.'); // Nouveau log 1
        
            const now = performance.now();
            if (now - lastDetectionTime < desiredFrameRate) {
                animationFrameId = requestAnimationFrame(detectAndDraw);
                return;
            }
            lastDetectionTime = now;
        
            if (!model || !webcamVideo.srcObject || !imagesLoaded) {
                // Ajoutons un log pour savoir pourquoi elle se termine t√¥t
                let reason = '';
                if (!model) reason += 'Mod√®le non charg√©. ';
                if (!webcamVideo.srcObject) reason += 'Webcam non pr√™te. ';
                if (!imagesLoaded) reason += 'Images 3D non charg√©es. ';
                console.log(`detectAndDraw: Terminaison anticip√©e - ${reason}`);
                animationFrameId = requestAnimationFrame(detectAndDraw);
                return;
            }
        
            // --- Dessine la vid√©o de la webcam sur le canvas en premier ---
            ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
            
            // Nouveau log 2 : V√©rifiez si nous arrivons ici
            console.log('detectAndDraw: Tentative de dessin de la webcam.'); 
            console.log(`Webcam video dimensions: ${webcamVideo.videoWidth}x${webcamVideo.videoHeight}`); // Nouveau log 3
        
            // Assurez-vous que videoWidth et videoHeight sont > 0 avant de dessiner
            if (webcamVideo.videoWidth > 0 && webcamVideo.videoHeight > 0) {
                ctx.drawImage(webcamVideo, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
            } else {
                console.warn('Webcam video dimensions are zero, cannot draw yet.');
            }
        
            const predictions = await model.estimateFaces(webcamVideo, { flipHorizontal: false, minDetectionConfidence: faceDetectionConfidence });

            let leftEyeVisible = false;
            let rightEyeVisible = false;
            let currentStatusMessage = 'Aucun visage d√©tect√©.';

            if (predictions.length > 0) {
                const face = predictions[0]; // On se concentre sur le premier visage d√©tect√©
                
                // --- Dessine le cadre de d√©limitation si activ√© ---
                if (showBoundingBox && face.box) {
                    drawBoundingBox(face.box, 'cyan'); // Cadre du visage en cyan
                }

                if (face.scaledMesh) {
                    leftEyeVisible = checkEyeOcclusion(face.scaledMesh, LEFT_EYE_CONTOUR_INDICES);
                    rightEyeVisible = checkEyeOcclusion(face.scaledMesh, RIGHT_EYE_CONTOUR_INDICES);
                    
                    // --- Dessine les points si activ√© ---
                    if (showLandmarks) {
                        // Dessiner tous les landmarks du visage
                        drawLandmarks(face.scaledMesh, 'rgba(255, 255, 0, 0.5)'); // Jaune semi-transparent

                        // Mettre en √©vidence les points des yeux avec leurs couleurs sp√©cifiques
                        for(const idx of LEFT_EYE_CONTOUR_INDICES) {
                            if(face.scaledMesh[idx]) {
                                const pt = face.scaledMesh[idx];
                                const x = pt[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                                const y = pt[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                                // Affiche la coordonn√©e Z √† c√¥t√© du point
                                ctx.fillStyle = 'red';
                                ctx.beginPath();
                                ctx.arc(x, y, 3, 0, 2 * Math.PI);
                                ctx.fill();
                                ctx.font = '10px Arial';
                                ctx.fillText(pt[2].toFixed(2), x + 5, y - 5); // Affiche Z
                            }
                        }
                        for(const idx of RIGHT_EYE_CONTOUR_INDICES) {
                            if(face.scaledMesh[idx]) {
                                const pt = face.scaledMesh[idx];
                                const x = pt[0] * (CANVAS_WIDTH / webcamVideo.videoWidth);
                                const y = pt[1] * (CANVAS_HEIGHT / webcamVideo.videoHeight);
                                ctx.fillStyle = 'blue';
                                ctx.beginPath();
                                ctx.arc(x, y, 3, 0, 2 * Math.PI);
                                ctx.fill();
                                ctx.font = '10px Arial';
                                ctx.fillText(pt[2].toFixed(2), x + 5, y - 5); // Affiche Z
                            }
                        }
                    }

                    // --- Mettre √† jour le statut d√©taill√© ---
                    const leftEyePointsCount = face.scaledMesh.filter((p, i) => LEFT_EYE_CONTOUR_INDICES.includes(i) && p[2] > visibilityThreshold).length;
                    const rightEyePointsCount = face.scaledMesh.filter((p, i) => RIGHT_EYE_CONTOUR_INDICES.includes(i) && p[2] > visibilityThreshold).length;
                    
                    currentStatusMessage = `Visage d√©tect√© (Conf: ${face.box.score.toFixed(2)}). `;
                    currentStatusMessage += `≈íil G: ${leftEyeVisible ? 'Visible' : 'Masqu√©'} (${leftEyePointsCount}/${LEFT_EYE_CONTOUR_INDICES.length}), `;
                    currentStatusMessage += `≈íil D: ${rightEyeVisible ? 'Visible' : 'Masqu√©'} (${rightEyePointsCount}/${RIGHT_EYE_CONTOUR_INDICES.length})`;

                } else {
                    currentStatusMessage = 'Visage d√©tect√©, mais donn√©es de points cl√©s absentes ou incompl√®tes. Ajustez la confiance ou l\'√©clairage.';
                }

            } else {
                currentStatusMessage = 'Aucun visage d√©tect√©.';
            }

            // --- Logique d'affichage 3D sur le canvas (si showLandmarks est d√©sactiv√©) ---
            if (!showLandmarks) {
                // Si on ne montre pas les landmarks, on applique la logique 3D principale
                // Effacer la vid√©o de la webcam pour montrer uniquement le rendu 3D
                ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT); 

                if (leftEyeVisible && !rightEyeVisible) {
                    ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                    currentStatusMessage += ' -> Image Gauche';
                } else if (!leftEyeVisible && rightEyeVisible) {
                    ctx.drawImage(imageRight, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                    currentStatusMessage += ' -> Image Droite';
                } else {
                    const twoEyesMode = document.querySelector('input[name="twoEyesMode"]:checked').value;
                    if (twoEyesMode === 'black') {
                        ctx.fillStyle = 'black';
                        ctx.fillRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> √âcran Noir';
                    } else if (twoEyesMode === 'sidebyside') {
                        ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH / 2, CANVAS_HEIGHT);
                        ctx.drawImage(imageRight, CANVAS_WIDTH / 2, 0, CANVAS_WIDTH / 2, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> C√¥t√© √† C√¥t√©';
                    } else if (twoEyesMode === 'mono') {
                        ctx.drawImage(imageLeft, 0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
                        currentStatusMessage += ' -> Image Unique';
                    }
                }
            } else {
                // Si showLandmarks est activ√©, la vid√©o de la webcam est d√©j√† dessin√©e.
                // On ajoute juste l'information de l'√©tat des yeux au statut.
                // Le message est d√©j√† construit plus haut.
            }

            updateStatusLog(currentStatusMessage);

            animationFrameId = requestAnimationFrame(detectAndDraw);
        }

        startButton.addEventListener('click', async () => {
            statusLogElement.value = '';
            lastStatusMessage = '';
            updateStatusLog('D√©marrage de l\'application...');
        
            if (!model) {
                await loadFaceMeshModel();
            }
            if (!model) {
                updateStatusLog('Impossible de continuer sans le mod√®le FaceMesh. Corrigez les erreurs.');
                console.error('Model not loaded, aborting startup.'); // Nouveau log
                return;
            }
        
            await setupWebcam();
            if (!webcamVideo.srcObject) {
                updateStatusLog('Impossible de continuer sans l\'acc√®s √† la webcam. Corrigez les permissions.');
                console.error('Webcam not ready, aborting startup.'); // Nouveau log
                return;
            }
            
            // Assurez-vous que la vid√©o est charg√©e avant de lancer detectAndDraw
            // C'est potentiellement le point de blocage !
            webcamVideo.onloadeddata = () => { // Utilisez 'loadeddata' car 'loadedmetadata' peut √™tre trop t√¥t
                console.log('Webcam video loadeddata event fired. Starting detection loop.');
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                }
                updateStatusLog('Webcam d√©marr√©e. D√©tection en cours...');
                animationFrameId = requestAnimationFrame(detectAndDraw);
            };
            // Si loadeddata ne se d√©clenche jamais, il y a un probl√®me.
            // Ajouter un timeout pour diagnostiquer si l'event ne se d√©clenche pas
            setTimeout(() => {
                if (!animationFrameId && webcamVideo.srcObject) {
                    console.warn("Webcam loadeddata event did not fire within expected time. Forcing detectAndDraw start.");
                    updateStatusLog('Webcam d√©marr√©e (force). D√©tection en cours...');
                    animationFrameId = requestAnimationFrame(detectAndDraw);
                }
            }, 3000); // Attendre 3 secondes
        });
        /* Fin du JavaScript int√©gr√© */
    </script>
</body>
</html>
